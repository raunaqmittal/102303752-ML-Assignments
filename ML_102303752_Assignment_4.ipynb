{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\rauna\\anaconda3\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\rauna\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.35.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting urllib3<3.0,>=2.5.0 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting trio~=0.30.0 (from selenium)\n",
      "  Downloading trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from selenium) (2025.7.14)\n",
      "Collecting typing_extensions~=4.14.0 (from selenium)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (24.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (3.7)\n",
      "Collecting outcome (from trio~=0.30.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\rauna\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
      "Downloading selenium-4.35.0-py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.6 MB 5.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.4/9.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.0/9.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.7/9.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 11.6 MB/s eta 0:00:00\n",
      "Downloading trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, urllib3, typing_extensions, outcome, trio, trio-websocket, selenium\n",
      "\n",
      "  Attempting uninstall: urllib3\n",
      "\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "\n",
      "   ----- ---------------------------------- 1/7 [urllib3]\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "   ----- ---------------------------------- 1/7 [urllib3]\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "   ----- ---------------------------------- 1/7 [urllib3]\n",
      "   ----- ---------------------------------- 1/7 [urllib3]\n",
      "   ----- ---------------------------------- 1/7 [urllib3]\n",
      "  Attempting uninstall: typing_extensions\n",
      "   ----- ---------------------------------- 1/7 [urllib3]\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "   ----- ---------------------------------- 1/7 [urllib3]\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "   ----- ---------------------------------- 1/7 [urllib3]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ----------- ---------------------------- 2/7 [typing_extensions]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------- ----------------- 4/7 [trio]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------- ----- 6/7 [selenium]\n",
      "   ---------------------------------------- 7/7 [selenium]\n",
      "\n",
      "Successfully installed outcome-1.3.0.post0 selenium-4.35.0 trio-0.30.0 trio-websocket-0.12.2 typing_extensions-4.14.1 urllib3-2.5.0 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install pandas\n",
    "!pip install selenium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XGLSU_BfIhd8"
   },
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "gEcxf2N3LVjE"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "BASE_URL = \"http://books.toscrape.com/catalogue/\"\n",
    "TOTAL_PAGES = 50\n",
    "\n",
    "def get_data_from_page(page_num):\n",
    "    page_data = []\n",
    "    current_page_url = f\"{BASE_URL}page-{page_num}.html\"\n",
    "\n",
    "    response = requests.get(current_page_url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    books = soup.find_all(\"article\", class_=\"product_pod\")\n",
    "    if not books:\n",
    "        return []\n",
    "\n",
    "    for book in books:\n",
    "        title_element = book.h3.a\n",
    "        title = title_element[\"title\"] if title_element else 'NaN'\n",
    "\n",
    "        price_element = book.find(\"p\", class_=\"price_color\")\n",
    "        price = price_element.get_text(strip=True) if price_element else 'NaN'\n",
    "\n",
    "        availability_element = book.find(\"p\", class_=\"instock availability\")\n",
    "        availability = availability_element.get_text(strip=True) if availability_element else 'NaN'\n",
    "\n",
    "        rating_element = book.find(\"p\", class_=\"star-rating\")\n",
    "        star_rating = rating_element[\"class\"][1] if rating_element and len(rating_element[\"class\"]) > 1 else 'NaN'\n",
    "\n",
    "        page_data.append({\n",
    "            \"Title\": title,\n",
    "            \"Price\": price,\n",
    "            \"Availability\": availability,\n",
    "            \"Star Rating\": star_rating\n",
    "        })\n",
    "\n",
    "    return page_data\n",
    "\n",
    "all_data = []\n",
    "for page in range(1, TOTAL_PAGES + 1):\n",
    "  all_data.extend(get_data_from_page(page))\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "if not df.empty:\n",
    "    df.head()\n",
    "    df.to_csv('book_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijl-dPSvMw5J"
   },
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Q4hDIllcODCi"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--headless')\n",
    "options.add_argument('--no-sandbox')\n",
    "options.add_argument('--disable-dev-shm-usage')\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://www.imdb.com/chart/top/\")\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "list_container = wait.until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, \"ul.ipc-metadata-list\"))\n",
    ")\n",
    "movies = list_container.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "movies_data = []\n",
    "for movie_item in movies:\n",
    "    title_text = movie_item.find_element(By.CSS_SELECTOR, \"h3.ipc-title__text\").text\n",
    "    rank_str, title = title_text.split(\". \", 1)\n",
    "\n",
    "    metadata_items = movie_item.find_elements(By.CSS_SELECTOR, \"span.cli-title-metadata-item\")\n",
    "    year_str = metadata_items[0].text\n",
    "\n",
    "    rating_str = movie_item.find_element(By.CSS_SELECTOR, \"span.ipc-rating-star\").text.split(\"\\n\")[0]\n",
    "\n",
    "    movies_data.append({\n",
    "        \"Rank\": int(rank_str),\n",
    "        \"Movie Title\": title,\n",
    "        \"Year of Release\": int(year_str),\n",
    "        \"IMDB Rating\": float(rating_str)\n",
    "    })\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "df = pd.DataFrame(movies_data)\n",
    "df = df.sort_values(by=\"Rank\").reset_index(drop=True)\n",
    "df.head()\n",
    "df.to_csv(\"imdb_top250.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEF_3YXt_fut"
   },
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "LCHW9MtNzK1Y"
   },
   "outputs": [],
   "source": [
    "def extract_temp_as_float(temp):\n",
    "\n",
    "    value = temp.replace(\"°C\", \"\").replace(\"°F\", \"\").strip()\n",
    "\n",
    "    value = value.replace(\"\\u00a0\", \"\").replace(\"\\xa0\", \"\")\n",
    "    return float(value)\n",
    "\n",
    "url = \"https://www.timeanddate.com/weather/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "tds = soup.find_all('td')\n",
    "results = []\n",
    "current_city = None\n",
    "weather_condition = \"\"\n",
    "\n",
    "for i, td in enumerate(tds):\n",
    "\n",
    "    if td.find('a'):\n",
    "        current_city = td.get_text(strip=True)\n",
    "\n",
    "        weather_condition = \"\"\n",
    "        for offset in range(1, 3):\n",
    "            if i + offset < len(tds):\n",
    "                img = tds[i + offset].find('img')\n",
    "                if img and img.get(\"alt\"):\n",
    "                    weather_condition = img[\"alt\"]\n",
    "                    break\n",
    "\n",
    "    elif 'rbi' in td.get('class', []) and current_city:\n",
    "        temp_str = td.get_text(strip=True)\n",
    "        try:\n",
    "            temp_float = extract_temp_as_float(temp_str)\n",
    "        except Exception as e:\n",
    "            temp_float = None\n",
    "        results.append({\n",
    "            \"City Name\": current_city,\n",
    "            \"Temperature\": temp_float,\n",
    "            \"Weather Condition\": weather_condition\n",
    "        })\n",
    "        current_city = None\n",
    "        weather_condition = \"\"\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.head()\n",
    "df.to_csv('weather.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOMZvXT4m54zxoeD/6jGFTW",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
